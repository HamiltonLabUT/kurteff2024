# kurteff2024
Brain viewer for Kurteff et al. 2024

**Citation:** Kurteff GL, Field AM, Asghar S, Tyler-Kabara EC, Clarke D, Weiner HL, Anderson AE, Watrous AJ, Buchanan RJ, Modur PN, Hamilton LS. Spatiotemporal mapping of auditory onsets during speech production. Journal of Neuroscience. 25 October 2024, e1109242024; [https://doi.org/10.1523/JNEUROSCI.1109-24.2024](https://doi.org/10.1523/JNEUROSCI.1109-24.2024)

## Abstract 
The human auditory cortex is organized according to the timing and spectral characteristics of speech sounds during speech perception. During listening, the posterior superior temporal gyrus is organized according to onset responses, which segment acoustic boundaries in speech, and sustained responses, which further process phonological content. When we speak, the auditory system is actively processing the sound of our own voice to detect and correct speech errors in real time. This manifests in neural recordings as suppression of auditory responses during speech production compared to perception, but whether this differentially affects onset and sustained temporal profiles is not known. Here we investigated this question using intracranial EEG recorded from seventeen pediatric, adolescent, and adult patients with medication-resistant epilepsy while they performed a reading/listening task. We identified onset and sustained responses to speech in bilateral auditory cortex and observed a selective suppression of onset responses during speech production. We conclude that onset responses provide a temporal landmark during speech perception that is redundant with forward prediction during speech production and are therefore suppressed. Phonological feature tuning in these “onset suppression” electrodes remained stable between perception and production. Notably, auditory onset responses and phonological feature tuning were present in the posterior insula during both speech perception and production, suggesting an anatomically and functionally separate auditory processing zone that we believe to be involved in multisensory integration during speech perception and feedback control.

## Funding 
Funding was provided by the National Institutes of Health National Institute on Deafness and Other Communication Disorders (1R01-DC018579, to L.S.H.) and by a William Orr Dingwall Foundation Dissertation Fellowship (to G.L.K.).

## Acknowledgments
The authors would like to thank the patients at Dell Children’s Medical Center, Texas Children’s Medical Center, and Dell Seton Medical Center for volunteering time during their hospital stay to participate in this research. We thank the members of the clinical team at Dell Children’s that assisted in data collection and/or patient referral: Timothy George, MD; Winson Ho, MD; Nancy Nussbaum, PhD; Rosario DeLeon, PhD; William Andy Schraegle, PhD; Fred Perkins, MD; Karen Keough, MD; Aaron Cardon, MD; Karen Skjei, MD; Teresa Ontiveros, RN, MSN; Cassidy Wink, RN; and Bethany Hepokoski, RN. We thank Maansi Desai, PhD for her assistance with data collection and manuscript edits. Lastly, we thank Stephanie Ries, PhD; Maya Henry, PhD, CCC-SLP; Rosemary A. Lester-Smith PhD, CCC-SLP; and Jun Wang, PhD for their feedback on early manuscript drafts. 
